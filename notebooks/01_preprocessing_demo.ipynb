{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e004ca7",
   "metadata": {
    "id": "9e004ca7"
   },
   "source": [
    "# Sleep-EDF Preprocessing (EEG → Epochs → NPZ)\n\nThis notebook converts **Sleep-EDF** EDF recordings into per-night `.npz` files (`X`, `y`) and an optional combined dataset (`X_all`, `y_all`, `night_ids_all`).\n\n**Pipeline:** EDF files → MNE preprocessing → 30s epochs → stage mapping → saved artifacts.\n\n## Preprocessing specifications (reproducible)\n\n- Dataset: Sleep-EDF Expanded (sleep-cassette subset)\n- Input files (not included in repo): `*PSG.edf` and `*Hypnogram.edf`\n- Channel: `EEG Fpz-Cz` (configurable via `CHANNEL`)\n- Bandpass: 0.5–40 Hz (configurable via `BANDPASS_HZ`)\n- Epoching: 30 seconds (configurable via `EPOCH_SEC`)\n- Stage mapping: W→0, N1→1, N2→2, N3(3+4 merged)→3, REM→4\n- Outputs:\n  - Per-night artifacts: `{night_id}.npz` with `X`, `y`, plus metadata fields (`channel`, `bandpass`, `epoch_sec`)\n  - Optional combined artifact: `sleep_edf_all_with_ids.npz` with `X`, `y`, `night_ids`\n\n### How to run (recommended)\n\nThis notebook is meant to be *readable documentation* of the preprocessing pipeline.\nFor automation / reproducibility, use the CLI entrypoint defined at the bottom:\n\n```bash\n# Preprocess raw EDF → per-night NPZ\npython Sleep_01_preprocessing_CLEAN.ipynb --preprocess --raw_dir <RAW_DIR> --out_dir <OUT_DIR>\n\n# Combine per-night NPZ → one dataset with night ids\npython Sleep_01_preprocessing_CLEAN.ipynb --combine --processed_dir <OUT_DIR> --out_path <OUT_PATH>\n```\n\n(If you convert this into a `.py` module later, these exact flags transfer cleanly.)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install numpy mne"
   ],
   "metadata": {
    "id": "7KjioDvIKWsZ"
   },
   "id": "7KjioDvIKWsZ",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e88c03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97e88c03",
    "outputId": "1cb25570-2f23-4ecb-f4ae-dc23a24c960d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RAW_DIR: /content/drive/MyDrive/sleep-insights/raw_edf/sleep-cassette\n",
      "Exists? True\n",
      "Files: ['processed']\n"
     ]
    }
   ],
   "source": [
    "# --- Setup: paths & constants ---\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# Configure a base directory so this runs on Colab *and* locally.\n",
    "# In Colab you can set: os.environ[\"SLEEP_BCI_BASEDIR\"] = \"/content/drive/MyDrive/sleep-insights\"\n",
    "BASE_DIR = os.getenv(\"SLEEP_BCI_BASEDIR\", \"/content/drive/MyDrive/sleep-insights\")\n",
    "\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"raw_edf\", \"sleep-cassette\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"processed\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"Exists?\", os.path.exists(RAW_DIR))\n",
    "print(\"Files:\", os.listdir(RAW_DIR)[:5] if os.path.exists(RAW_DIR) else \"NO DIR\")\n",
    "\n",
    "\n",
    "# Sleep stage mapping (merge stages 3 & 4 → N3)\n",
    "STAGE_MAP = {\n",
    "    \"Sleep stage W\": 0,  # Wake\n",
    "    \"Sleep stage 1\": 1,  # N1\n",
    "    \"Sleep stage 2\": 2,  # N2\n",
    "    \"Sleep stage 3\": 3,  # N3\n",
    "    \"Sleep stage 4\": 3,  # N3 (merged)\n",
    "    \"Sleep stage R\": 4,  # REM\n",
    "}\n",
    "\n",
    "# Target channel & epoch params\n",
    "CHANNEL = \"EEG Fpz-Cz\"\n",
    "BANDPASS_HZ = (0.5, 40.0)\n",
    "EPOCH_SEC = 30\n",
    "SFREQ_TARGET = None  # keep original; set e.g. 100 to resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191a8919",
   "metadata": {
    "id": "191a8919"
   },
   "outputs": [],
   "source": [
    "def build_hypnogram_lookup(raw_dir: str) -> dict:\n    \"\"\"Map a PSG prefix like 'SC4001E' to the corresponding hypnogram EDF path.\"\"\"\n    if not os.path.exists(raw_dir):\n        raise FileNotFoundError(f\"RAW_DIR does not exist: {raw_dir}\")\n\n    hyp_files = glob.glob(os.path.join(raw_dir, \"*Hypnogram.edf\"))\n    lookup = {}\n    for h in hyp_files:\n        # Example filename: SC4001EC-Hypnogram.edf → key 'SC4001E'\n        prefix = os.path.basename(h).split(\"-\")[0]      # SC4001EC\n        lookup[prefix[:-1]] = h                         # SC4001E\n    return lookup\n\n\ndef process_one_night(psg_path: str, hyp_path: str) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Load PSG + hypnogram EDF, return (X, y) for this night.\"\"\"\n    raw = mne.io.read_raw_edf(psg_path, preload=True, verbose=False)\n\n    ann = mne.read_annotations(hyp_path)\n    raw.set_annotations(ann)\n\n    # Keep one EEG channel\n    raw.pick([CHANNEL])\n\n    # Optional resampling (disabled by default)\n    if SFREQ_TARGET is not None:\n        raw.resample(SFREQ_TARGET, verbose=False)\n\n    # Basic filtering\n    raw.filter(BANDPASS_HZ[0], BANDPASS_HZ[1], verbose=False)\n\n    # Convert annotations → events\n    events, event_id = mne.events_from_annotations(raw, verbose=False)\n\n    # Keep only labels we can map\n    valid_event_id = {k: v for k, v in event_id.items() if k in STAGE_MAP}\n    if not valid_event_id:\n        raise ValueError(\"No valid sleep stages found in hypnogram annotations.\")\n\n    epochs = mne.Epochs(\n        raw,\n        events,\n        event_id=valid_event_id,\n        tmin=0,\n        tmax=EPOCH_SEC,\n        baseline=None,\n        preload=True,\n        verbose=False,\n    )\n\n    # Get epoch data\n    X = epochs.get_data()\n\n    # Standardize epoch length if off-by-one occurs\n    if X.shape[-1] > 3000:\n        X = X[:, :, :3000]\n\n    # Map event integers back to annotation strings, then to STAGE_MAP values\n    inv_event_id = {v: k for k, v in valid_event_id.items()}\n    y = np.array([STAGE_MAP[inv_event_id[e]] for e in epochs.events[:, 2]], dtype=np.int64)\n\n    return X, y\n\n\ndef preprocess_all_nights(raw_dir: str, out_dir: str) -> tuple[int, int]:\n    \"\"\"Iterate PSG files, save per-night X/y npz files. Returns (kept, skipped).\n\n    Fail-fast behavior:\n      - Raises if raw_dir does not exist or contains no PSG EDF files.\n      - Raises if no hypnograms are found.\n    \"\"\"\n    if not os.path.exists(raw_dir):\n        raise FileNotFoundError(f\"RAW_DIR does not exist: {raw_dir}\")\n\n    os.makedirs(out_dir, exist_ok=True)\n\n    psg_files = sorted(glob.glob(os.path.join(raw_dir, \"*PSG.edf\")))\n    if not psg_files:\n        sample = os.listdir(raw_dir)[:10] if os.path.isdir(raw_dir) else []\n        raise ValueError(\n            \"No PSG EDF files found.\n\"\n            f\"Expected pattern: {os.path.join(raw_dir, '*PSG.edf')}\n\"\n            f\"Directory sample: {sample}\"\n        )\n\n    hyp_lookup = build_hypnogram_lookup(raw_dir)\n    if not hyp_lookup:\n        raise ValueError(\n            \"No hypnogram EDF files found.\n\"\n            f\"Expected pattern: {os.path.join(raw_dir, '*Hypnogram.edf')}\"\n        )\n\n    print(f\"Found {len(psg_files)} PSG files\")\n    print(f\"Found {len(hyp_lookup)} hypnogram keys\")\n\n    kept, skipped = 0, 0\n\n    for psg in psg_files:\n        base = os.path.basename(psg).replace(\"-PSG.edf\", \"\")  # SC4001E0\n        key = base[:-1]                                       # SC4001E\n\n        hyp = hyp_lookup.get(key)\n        if hyp is None:\n            print(f\"❌ Missing hypnogram for {base}, skipping\")\n            skipped += 1\n            continue\n\n        try:\n            X, y = process_one_night(psg, hyp)\n\n            out_path = os.path.join(out_dir, f\"{base}.npz\")\n            np.savez(\n                out_path,\n                X=X,\n                y=y,\n                channel=CHANNEL,\n                bandpass=BANDPASS_HZ,\n                epoch_sec=EPOCH_SEC,\n                sfreq_target=SFREQ_TARGET,\n            )\n\n            print(f\"✅ Saved {os.path.basename(out_path)} | epochs: {len(y)}\")\n            kept += 1\n\n        except Exception as e:\n            print(f\"❌ Error processing {base}: {e}\")\n            skipped += 1\n\n    print(\"\n======================\")\n    print(\"✅ Done preprocessing\")\n    print(f\"Kept nights: {kept}\")\n    print(f\"Skipped nights: {skipped}\")\n    return kept, skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0c0463",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d0c0463",
    "outputId": "2ebe996b-f6fe-4bcc-fe0d-db255be9c2b6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 0 PSG files\n",
      "Found 0 hypnogram keys\n",
      "\n",
      "======================\n",
      "✅ Done preprocessing\n",
      "Kept nights: 0\n",
      "Skipped nights: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Run preprocessing ---\n",
    "# This writes one .npz per night into OUT_DIR.\n",
    "kept, skipped = preprocess_all_nights(RAW_DIR, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982860f",
   "metadata": {
    "id": "a982860f"
   },
   "outputs": [],
   "source": [
    "def combine_nights(processed_dir: str, out_path: str) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Combine nightly .npz files into one dataset + night_ids.\"\"\"\n    if not os.path.exists(processed_dir):\n        raise FileNotFoundError(f\"processed_dir does not exist: {processed_dir}\")\n\n    night_files = sorted([\n        f for f in glob.glob(os.path.join(processed_dir, \"*.npz\"))\n        if \"sleep_edf_all\" not in os.path.basename(f)\n    ])\n\n    if not night_files:\n        raise FileNotFoundError(\"No nightly .npz files found. Run preprocessing first.\")\n\n    print(f\"Found {len(night_files)} nightly files\")\n\n    X_all, y_all, night_ids_all = [], [], []\n\n    for night_idx, f in enumerate(night_files):\n        data = np.load(f, allow_pickle=True)\n        X = data[\"X\"]\n        y = data[\"y\"]\n\n        # Fix off-by-one issue if present (3001 -> 3000)\n        if X.shape[-1] == 3001:\n            X = X[:, :, :3000]\n\n        if X.shape[0] != y.shape[0]:\n            raise ValueError(f\"Mismatch in {f}: X has {X.shape[0]} epochs but y has {y.shape[0]} labels\")\n\n        X_all.append(X)\n        y_all.append(y)\n        night_ids_all.append(np.full(len(y), night_idx, dtype=np.int32))\n\n        print(f\"{os.path.basename(f)} → epochs: {len(y)} | night_id: {night_idx}\")\n\n    X_all = np.concatenate(X_all, axis=0)\n    y_all = np.concatenate(y_all, axis=0)\n    night_ids_all = np.concatenate(night_ids_all, axis=0)\n\n    np.savez(out_path, X=X_all, y=y_all, night_ids=night_ids_all)\n\n    print(\"\\n✅ Final dataset shapes\")\n    print(\"X:\", X_all.shape)\n    print(\"y:\", y_all.shape)\n    print(\"night_ids:\", night_ids_all.shape)\n    print(f\"✅ Saved combined dataset: {out_path}\")\n\n    return X_all, y_all, night_ids_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a20d01",
   "metadata": {
    "id": "11a20d01"
   },
   "outputs": [],
   "source": [
    "# --- Combine into one dataset (optional) ---\n",
    "COMBINED_PATH = os.path.join(OUT_DIR, \"sleep_edf_all_with_ids.npz\")\n",
    "X_all, y_all, night_ids_all = combine_nights(OUT_DIR, COMBINED_PATH)\n",
    "\n",
    "# Minimal sanity check\n",
    "print(\"Label counts:\", dict(zip(*np.unique(y_all, return_counts=True))))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- CLI entrypoint (optional, for reproducible runs) ---\n# This cell lets you run preprocessing/combining as a script-like interface.\n# In a notebook kernel, it will NOT auto-run (guarded by \"__file__\" check).\n#\n# Example usage after you export this notebook to a .py script:\n#   python Sleep_01_preprocessing_CLEAN.py --preprocess --raw_dir data/raw/sleep-cassette --out_dir data/processed\n#   python Sleep_01_preprocessing_CLEAN.py --combine --processed_dir data/processed --out_path data/processed/sleep_edf_all_with_ids.npz\n\nimport argparse\n\ndef cli(argv=None):\n    parser = argparse.ArgumentParser(description=\"Sleep-EDF preprocessing utilities\")\n    parser.add_argument(\"--preprocess\", action=\"store_true\", help=\"Run raw EDF → per-night NPZ preprocessing\")\n    parser.add_argument(\"--combine\", action=\"store_true\", help=\"Combine per-night NPZ into one dataset with night_ids\")\n\n    parser.add_argument(\"--raw_dir\", type=str, default=RAW_DIR, help=\"Directory containing *PSG.edf and *Hypnogram.edf\")\n    parser.add_argument(\"--out_dir\", type=str, default=OUT_DIR, help=\"Output directory for per-night .npz files\")\n    parser.add_argument(\"--processed_dir\", type=str, default=OUT_DIR, help=\"Directory containing per-night .npz files\")\n    parser.add_argument(\"--out_path\", type=str, default=os.path.join(OUT_DIR, \"sleep_edf_all_with_ids.npz\"),\n                        help=\"Path to write combined dataset .npz\")\n\n    args = parser.parse_args(argv)\n\n    if not (args.preprocess or args.combine):\n        parser.error(\"Choose an action: --preprocess and/or --combine\")\n\n    if args.preprocess:\n        preprocess_all_nights(args.raw_dir, args.out_dir)\n\n    if args.combine:\n        combine_nights(args.processed_dir, args.out_path)\n\n# Only auto-run when executed as a script (not in an interactive notebook kernel).\nif __name__ == \"__main__\" and \"__file__\" in globals():\n    cli()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}